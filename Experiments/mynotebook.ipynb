{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m        \u001b[38;5;66;03m# For numerical operations\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m       \u001b[38;5;66;03m# For data manipulation and analysis\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m  \u001b[38;5;66;03m# For data visualization\u001b[39;00m\n\u001b[0;32m      5\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Importing WordCloud for text visualization\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np        # For numerical operations\n",
    "import pandas as pd       # For data manipulation and analysis\n",
    "import matplotlib.pyplot as plt  # For data visualization\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing WordCloud for text visualization\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Importing NLTK for natural language processing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords    # For stopwords\n",
    "\n",
    "\n",
    "# Downloading NLTK data\n",
    "nltk.download('stopwords')   # Downloading stopwords data\n",
    "nltk.download('punkt')       # Downloading tokenizer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel= \"sigmoid\", gamma  = 1.0)\n",
    "knc = KNeighborsClassifier()\n",
    "mnb = MultinomialNB()\n",
    "dtc = DecisionTreeClassifier(max_depth = 5)\n",
    "lrc = LogisticRegression(solver = 'liblinear', penalty = 'l1')\n",
    "rfc = RandomForestClassifier(n_estimators = 50, random_state = 2 )\n",
    "abc = AdaBoostClassifier(n_estimators = 50, random_state = 2)\n",
    "bc = BaggingClassifier(n_estimators = 50, random_state = 2)\n",
    "etc = ExtraTreesClassifier(n_estimators = 50, random_state = 2)\n",
    "gbdt = GradientBoostingClassifier(n_estimators = 50, random_state = 2)    \n",
    "xgb  = XGBClassifier(n_estimators = 50, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    'SVC': svc,\n",
    "    'KNN': knc,\n",
    "    'NB': mnb,\n",
    "    'DT': dtc,\n",
    "    'LR': lrc,\n",
    "    'RF': rfc,\n",
    "    'Adaboost': abc,\n",
    "    'Bgc': bc,\n",
    "    'ETC': etc,\n",
    "    'GBDT': gbdt,\n",
    "    'xgb': xgb\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "def train_classifier(clfs, X_train, y_train, X_test, y_test):\n",
    "    clfs.fit(X_train,y_train)\n",
    "    y_pred = clfs.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    return accuracy , precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For:  SVC\n",
      "Accuracy:  0.9661508704061895\n",
      "Precision:  0.9327731092436975\n",
      "\n",
      "For:  KNN\n",
      "Accuracy:  0.9274661508704062\n",
      "Precision:  1.0\n",
      "\n",
      "For:  NB\n",
      "Accuracy:  0.9709864603481625\n",
      "Precision:  0.9655172413793104\n",
      "\n",
      "For:  DT\n",
      "Accuracy:  0.9381044487427466\n",
      "Precision:  0.9021739130434783\n",
      "\n",
      "For:  LR\n",
      "Accuracy:  0.9632495164410058\n",
      "Precision:  0.9629629629629629\n",
      "\n",
      "For:  RF\n",
      "Accuracy:  0.971953578336557\n",
      "Precision:  0.943089430894309\n",
      "\n",
      "For:  Adaboost\n",
      "Accuracy:  0.9613152804642167\n",
      "Precision:  0.9375\n",
      "\n",
      "For:  Bgc\n",
      "Accuracy:  0.965183752417795\n",
      "Precision:  0.9180327868852459\n",
      "\n",
      "For:  ETC\n",
      "Accuracy:  0.9729206963249516\n",
      "Precision:  0.9296875\n",
      "\n",
      "For:  GBDT\n",
      "Accuracy:  0.9506769825918762\n",
      "Precision:  0.9393939393939394\n",
      "\n",
      "For:  xgb\n",
      "Accuracy:  0.9709864603481625\n",
      "Precision:  0.9576271186440678\n"
     ]
    }
   ],
   "source": [
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "for name , clfs in clfs.items():\n",
    "    current_accuracy, current_precision = train_classifier(clfs, X_train, y_train, X_test, y_test)\n",
    "    print()\n",
    "    print(\"For: \", name)\n",
    "    print(\"Accuracy: \", current_accuracy)\n",
    "    print(\"Precision: \", current_precision)\n",
    "    \n",
    "    accuracy_scores.append(current_accuracy)\n",
    "    precision_scores.append(current_precision)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
